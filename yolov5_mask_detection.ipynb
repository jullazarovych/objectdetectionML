{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "yXj1Zf0uwd73",
        "R0qapgi6N-lB",
        "o-_yQZ6vw9ZU",
        "18kJuY6FE-Iq",
        "8jNfOo3XuZvo",
        "Co8bT_FTvrLW"
      ],
      "authorship_tag": "ABX9TyMG4mSFZEWMU1OC/Wi+2wd8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jullazarovych/objectdetectionML/blob/main/yolov5_mask_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Git**"
      ],
      "metadata": {
        "id": "yXj1Zf0uwd73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.ssh\n",
        "!chmod 700 ~/.ssh\n",
        "\n",
        "config_content = \"\"\"\n",
        "Host github.com\n",
        "    HostName github.com\n",
        "    User git\n",
        "    IdentityFile ~/.ssh/id_rsa\n",
        "    StrictHostKeyChecking no\n",
        "\"\"\"\n",
        "\n",
        "with open('/root/.ssh/config', 'w') as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "!chmod 600 ~/.ssh/config\n",
        "!chmod 600 ~/.ssh/id_rsa"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ePxfO679F4eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ssh -T git@github.com"
      ],
      "metadata": {
        "id": "V05UlFisN04U",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone git@github.com:jullazarovych/objectdetectionML.git\n",
        "\n",
        "!git config --global user.name \"yuliiaLazarovych\"\n",
        "!git config --global user.email \"yuliia.lazarovych.22@pnu.edu.ua\""
      ],
      "metadata": {
        "id": "7TE_NirwifEv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Xsdb5he9LpKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/objectdetectionML"
      ],
      "metadata": {
        "id": "1-s6cjqNivC_",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "status = !git status --porcelain\n",
        "merge_head = !ls .git/MERGE_HEAD 2>/dev/null || echo \"no merge\"\n",
        "\n",
        "if not status and \"no merge\" in merge_head[0]:\n",
        "    print(\"no conflicts\")\n",
        "elif \"MERGE_HEAD\" in str(merge_head):\n",
        "    print(\"uncomplited merge\")\n",
        "    !git status\n",
        "else:\n",
        "    print(\"there are changes, but not conflicts\")\n",
        "    !git status"
      ],
      "metadata": {
        "id": "XM_i7J-XMj5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/MyDrive/Colab Notebooks/yolov5_mask_detection.ipynb\" /content/objectdetectionML/\n",
        "%cd /content/objectdetectionML\n",
        "!git add -f yolov5_mask_detection.ipynb\n",
        "!git commit -m \"added training&testing on ordinary dataset & with augmentation, LIME explanation included\"\n",
        "!git push origin main"
      ],
      "metadata": {
        "id": "pJu9DrlLH1MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp -r runs /content/drive/MyDrive/yolo_data/"
      ],
      "metadata": {
        "id": "apcP5GwDjIgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing & importing YOLOv5 & necessary utils**"
      ],
      "metadata": {
        "id": "pknR9bX9un1u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "5YUwDdBv2m4n"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import xml.etree.ElementTree as ET\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.segmentation import mark_boundaries, slic\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "lXfZLouPC1NJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "PP0Xadtp3ET0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/drive/MyDrive/yolo_data/archive.zip -d /content/drive/MyDrive/yolo_data/"
      ],
      "metadata": {
        "id": "FVgDopJl3KAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing YOLOv5 on standart COCO categories**"
      ],
      "metadata": {
        "id": "jA2LVTy-Ezen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO('yolov5m.pt')"
      ],
      "metadata": {
        "id": "BdGCI0Ze3M1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_test_folder = Path('/content/drive/MyDrive/yolo_data/test_data')\n",
        "image_files = list(image_test_folder.glob(\"*.jpg\")) + list(image_test_folder.glob(\"*.jpeg\"))"
      ],
      "metadata": {
        "id": "u4hxfcrZ3OAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(image_files)\n",
        "\n",
        "for image_file in image_files[:10]:\n",
        "    results = model(image_file)\n",
        "    img_with_boxes = results[0].plot()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CQBcUxxl3PIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparing annotations in YOLO format, splitting dataset**"
      ],
      "metadata": {
        "id": "K-yJ-k59FHn_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xml_folder = '/content/drive/MyDrive/yolo_data/annotations'\n",
        "txt_folder = '/content/drive/MyDrive/yolo_data/labelfull'\n",
        "image_folder = '/content/drive/MyDrive/yolo_data/images'\n",
        "os.makedirs(txt_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "SXzgyzyI3SeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"with_mask\", \"without_mask\", \"mask_weared_incorrect\"]\n",
        "output_dir = \"/content/drive/MyDrive/yolo_data\""
      ],
      "metadata": {
        "id": "WBCqkAKkDseb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_bbox(size, box):\n",
        "    dw = 1.0 / size[0]\n",
        "    dh = 1.0 / size[1]\n",
        "    xmin, ymin, xmax, ymax = box\n",
        "    x_center = (xmin + xmax) / 2.0\n",
        "    y_center = (ymin + ymax) / 2.0\n",
        "    w = xmax - xmin\n",
        "    h = ymax - ymin\n",
        "    return (x_center * dw, y_center * dh, w * dw, h * dh)"
      ],
      "metadata": {
        "id": "B5VMA_PI3Tdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_annotations_to_yolo(xml_folder, txt_folder):\n",
        "    os.makedirs(txt_folder, exist_ok=True)\n",
        "\n",
        "    for file in os.listdir(xml_folder):\n",
        "        if not file.endswith(\".xml\"):\n",
        "            continue\n",
        "\n",
        "        in_file = os.path.join(xml_folder, file)\n",
        "        tree = ET.parse(in_file)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        size = root.find('size')\n",
        "        w = int(size.find('width').text)\n",
        "        h = int(size.find('height').text)\n",
        "        filename = root.find('filename').text\n",
        "        txt_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "        txt_path = os.path.join(txt_folder, txt_filename)\n",
        "\n",
        "        with open(txt_path, \"w\") as out_file:\n",
        "            for obj in root.findall('object'):\n",
        "                cls_name = obj.find('name').text\n",
        "                if cls_name not in classes:\n",
        "                    continue\n",
        "                cls_id = classes.index(cls_name)\n",
        "                xmlbox = obj.find('bndbox')\n",
        "                b = (\n",
        "                    int(xmlbox.find('xmin').text),\n",
        "                    int(xmlbox.find('ymin').text),\n",
        "                    int(xmlbox.find('xmax').text),\n",
        "                    int(xmlbox.find('ymax').text)\n",
        "                )\n",
        "                bb = convert_bbox((w, h), b)\n",
        "                out_file.write(f\"{cls_id} {bb[0]:.6f} {bb[1]:.6f} {bb[2]:.6f} {bb[3]:.6f}\\n\")"
      ],
      "metadata": {
        "id": "8xpK4rJRCI3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_annotations_to_yolo(xml_folder, txt_folder)"
      ],
      "metadata": {
        "id": "QiZ0uNysCKrQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = [f for f in os.listdir(image_folder) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "train_imgs, val_imgs = train_test_split(images, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "az6hL16cCMMA",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def move_files(file_list, src_img, src_lbl, dst_img, dst_lbl):\n",
        "    os.makedirs(dst_img, exist_ok=True)\n",
        "    os.makedirs(dst_lbl, exist_ok=True)\n",
        "    for file in file_list:\n",
        "        shutil.move(os.path.join(src_img, file), os.path.join(dst_img, file))\n",
        "        label_file = os.path.splitext(file)[0] + '.txt'\n",
        "        shutil.move(os.path.join(src_lbl, label_file), os.path.join(dst_lbl, label_file))"
      ],
      "metadata": {
        "id": "ZcZDwwRKCNxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "txt_folder_out='/content/drive/MyDrive/yolo_data/labels'"
      ],
      "metadata": {
        "id": "FIszvhaJgBOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(txt_folder_out, exist_ok=True)"
      ],
      "metadata": {
        "id": "ubiffxIvgtiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"move_files(train_imgs,\n",
        "           image_folder, txt_folder,\n",
        "           os.path.join(output_dir, \"images/train\"),\n",
        "           os.path.join(output_dir, \"labels/train\"))\n",
        "\n",
        "move_files(val_imgs,\n",
        "           image_folder, txt_folder,\n",
        "           os.path.join(output_dir, \"images/val\"),\n",
        "           os.path.join(output_dir, \"labels/val\"))\"\""
      ],
      "metadata": {
        "id": "MVEuYJ2jCPz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_labels_for_images(img_dir, label_src, label_dst):\n",
        "    os.makedirs(label_dst, exist_ok=True)\n",
        "\n",
        "    image_files = [f for f in os.listdir(img_dir)\n",
        "                   if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
        "\n",
        "    copied_count = 0\n",
        "\n",
        "    for img_name in image_files:\n",
        "        base_name = os.path.splitext(img_name)[0]\n",
        "\n",
        "        label_filename = base_name + \".txt\"\n",
        "        label_src_path = os.path.join(label_src, label_filename)\n",
        "        label_dst_path = os.path.join(label_dst, label_filename)\n",
        "\n",
        "        if os.path.exists(label_src_path):\n",
        "            shutil.copy2(label_src_path, label_dst_path)\n",
        "            copied_count += 1\n",
        "            print(f\"Copied: {label_filename}\")\n",
        "        else:\n",
        "            print(f\"Warning: Label missing for {img_name}\")\n",
        "\n",
        "    print(f\"Total labels copied: {copied_count}\")\n",
        "    return copied_count"
      ],
      "metadata": {
        "id": "IeEQxNkXiuT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs=\"/content/drive/MyDrive/yolo_data/images/train\"\n",
        "val_imgs=\"/content/drive/MyDrive/yolo_data/images/val\"\n",
        "label_src=\"/content/drive/MyDrive/yolo_data/labelfull\""
      ],
      "metadata": {
        "id": "6hwl633zjJyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_labels_for_images(train_imgs, label_src, \"/content/drive/MyDrive/yolo_data/labels/train\")\n",
        "copy_labels_for_images(val_imgs, label_src, \"/content/drive/MyDrive/yolo_data/labels/val\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_cA_PQEeiuiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training & testing YOLOv5**"
      ],
      "metadata": {
        "id": "R0qapgi6N-lB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(data=\"/content/drive/MyDrive/yolo_data/mask_detection.yaml\", epochs=50, imgsz=640, batch=8)"
      ],
      "metadata": {
        "id": "INEASM6WN-Jr",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom = YOLO(\"/content/drive/MyDrive/yolo_data/best.pt\") #possible data leakage"
      ],
      "metadata": {
        "id": "drkXo84eQkUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom2 = YOLO(\"/content/drive/MyDrive/yolo_data/yolo_training_results2/train2/weights/best.pt\")"
      ],
      "metadata": {
        "id": "BbvxuS5Ltvzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destination_dir = '/content/drive/MyDrive/yolo_data/yolo_training_results2'"
      ],
      "metadata": {
        "id": "UySP1AK6y8sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(os.path.dirname(destination_dir), exist_ok=True)"
      ],
      "metadata": {
        "id": "Z1rbPxwMzCY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = '/content/runs'\n",
        "shutil.copytree(source_dir, destination_dir)"
      ],
      "metadata": {
        "id": "IrWG4r5vzHuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_custom2.predict(\n",
        "    source='/content/drive/MyDrive/yolo_data/images/val',\n",
        "    save=True,\n",
        "    save_txt=True,\n",
        "    save_conf=True,\n",
        "    project='prediction2',\n",
        "    name='yolov5m_predictions',\n",
        "    exist_ok=True\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "h2-zBUDtMvL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/prediction2 /content/drive/MyDrive/yolo_data/"
      ],
      "metadata": {
        "id": "2jpNQI0NUkOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing YOLO on custom dataset, TP, TN, FP, FN**"
      ],
      "metadata": {
        "id": "SdiMC_I2uDKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_image_folder = Path(\"/content/drive/MyDrive/yolo_data/images/val\")\n",
        "\n",
        "val_images = list(val_image_folder.glob(\"*.jpg\")) + list(val_image_folder.glob(\"*.png\"))\n",
        "\n",
        "random.shuffle(val_images)\n",
        "selected_images = val_images[:10]\n",
        "\n",
        "for img_path in selected_images:\n",
        "    original_img = cv2.imread(str(img_path))\n",
        "    results = model_custom(img_path)\n",
        "    img_with_boxes = results[0].plot()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Original image: {img_path.name}\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(f\"Predictions for: {img_path.name}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "b3t-3YTbqWL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_yolo_labels(txt_path, img_shape):\n",
        "    h, w = img_shape[:2]\n",
        "    boxes = []\n",
        "    if not txt_path.exists():\n",
        "        return boxes\n",
        "    with open(txt_path, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            cls_id, cx, cy, bw, bh = map(float, parts)\n",
        "            xmin = int((cx - bw / 2) * w)\n",
        "            ymin = int((cy - bh / 2) * h)\n",
        "            xmax = int((cx + bw / 2) * w)\n",
        "            ymax = int((cy + bh / 2) * h)\n",
        "            boxes.append([int(cls_id), xmin, ymin, xmax, ymax])\n",
        "    return boxes\n",
        "\n",
        "def calculate_iou(box1, box2):\n",
        "    xA = max(box1[1], box2[1])\n",
        "    yA = max(box1[2], box2[2])\n",
        "    xB = min(box1[3], box2[3])\n",
        "    yB = min(box1[4], box2[4])\n",
        "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
        "    box1Area = (box1[3] - box1[1]) * (box1[4] - box1[2])\n",
        "    box2Area = (box2[3] - box2[1]) * (box2[4] - box2[2])\n",
        "    unionArea = float(box1Area + box2Area - interArea)\n",
        "    return interArea / unionArea if unionArea != 0 else 0"
      ],
      "metadata": {
        "id": "8tsLJWq-W01X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions_with_stats(\n",
        "    model, val_image_folder, labels_folder, classes,\n",
        "    num_images=10, iou_thresh=0.5, conf_thresh=0.25\n",
        "):\n",
        "    val_images = list(Path(val_image_folder).glob(\"*.jpg\")) + list(Path(val_image_folder).glob(\"*.png\"))\n",
        "    random.shuffle(val_images)\n",
        "    selected_images = val_images[:num_images]\n",
        "\n",
        "    for img_path in selected_images:\n",
        "        original_img = cv2.imread(str(img_path))\n",
        "        image_h, image_w = original_img.shape[:2]\n",
        "\n",
        "        txt_path = Path(labels_folder) / (img_path.stem + \".txt\")\n",
        "        gt_boxes = load_yolo_labels(txt_path, original_img.shape)\n",
        "\n",
        "        results = model(img_path)[0]\n",
        "        pred_boxes = []\n",
        "\n",
        "        for box in results.boxes:\n",
        "            if box.conf.item() < conf_thresh:\n",
        "                continue\n",
        "            cls = int(box.cls.item())\n",
        "            xmin, ymin, xmax, ymax = map(int, box.xyxy[0])\n",
        "            pred_boxes.append([cls, xmin, ymin, xmax, ymax])\n",
        "\n",
        "        matched_gt = set()\n",
        "        matched_pred = set()\n",
        "        fn_count = [0] * len(classes)\n",
        "        fp_count = [0] * len(classes)\n",
        "\n",
        "        for gi, gt in enumerate(gt_boxes):\n",
        "            best_iou = 0\n",
        "            best_pi = -1\n",
        "            for pi, pred in enumerate(pred_boxes):\n",
        "                if pred[0] != gt[0] or pi in matched_pred:\n",
        "                    continue\n",
        "                iou = calculate_iou(gt, pred)\n",
        "                if iou > best_iou:\n",
        "                    best_iou = iou\n",
        "                    best_pi = pi\n",
        "            if best_iou >= iou_thresh:\n",
        "                matched_gt.add(gi)\n",
        "                matched_pred.add(best_pi)\n",
        "            else:\n",
        "                fn_count[gt[0]] += 1\n",
        "\n",
        "        for pi, pred in enumerate(pred_boxes):\n",
        "            if pi not in matched_pred:\n",
        "                fp_count[pred[0]] += 1\n",
        "\n",
        "        img_gt = original_img.copy()\n",
        "        for cls, xmin, ymin, xmax, ymax in gt_boxes:\n",
        "            cv2.rectangle(img_gt, (xmin, ymin), (xmax, ymax), (0, 255, 0), 2)\n",
        "            cv2.putText(img_gt, classes[cls], (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "\n",
        "        img_pred = original_img.copy()\n",
        "        for cls, xmin, ymin, xmax, ymax in pred_boxes:\n",
        "            cv2.rectangle(img_pred, (xmin, ymin), (xmax, ymax), (0, 0, 255), 2)\n",
        "            cv2.putText(img_pred, classes[cls], (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
        "\n",
        "        plt.figure(figsize=(14, 6))\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.imshow(cv2.cvtColor(img_gt, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"GT for {img_path.name}\")\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.imshow(cv2.cvtColor(img_pred, cv2.COLOR_BGR2RGB))\n",
        "        plt.title(f\"Predictions for {img_path.name}\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Stats for: {img_path.name}\")\n",
        "        for i, class_name in enumerate(classes):\n",
        "            if fn_count[i] > 0 or fp_count[i] > 0:\n",
        "                print(f\" - {class_name}: FN={fn_count[i]}, FP={fp_count[i]}\")\n",
        "        print(\"â€”\" * 40)"
      ],
      "metadata": {
        "id": "GKX1uTHzWRPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_predictions_with_stats(\n",
        "    model=model_custom2,\n",
        "    val_image_folder=\"/content/drive/MyDrive/yolo_data/images/val\",\n",
        "    labels_folder=\"/content/drive/MyDrive/yolo_data/labels/val\",\n",
        "    classes=classes\n",
        ")"
      ],
      "metadata": {
        "id": "M2YQwmdPW3VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_custom(\"/content/drive/MyDrive/yolo_data/test_data/fmask4.jpg\")\n",
        "img_with_boxes = results[0].plot()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Predicted Bounding Boxes\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ISTQi99JUug0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_confusion_stats(model):\n",
        "    model = model\n",
        "    metrics = model.val()\n",
        "\n",
        "    cm = metrics.confusion_matrix.matrix\n",
        "\n",
        "    class_names = metrics.names\n",
        "    stats = []\n",
        "\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        TP = cm[i, i]\n",
        "        FP = cm[:, i].sum() - TP\n",
        "        FN = cm[i, :].sum() - TP\n",
        "        TN = cm.sum() - (TP + FP + FN)\n",
        "        stats.append({\n",
        "            'Class': class_name,\n",
        "            'TP': int(TP),\n",
        "            'FP': int(FP),\n",
        "            'FN': int(FN),\n",
        "            'TN': int(TN),\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(stats)\n",
        "    return df, metrics"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lKf3XA58exIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_stats(df_stats, class_names):\n",
        "    plt.style.use('default')\n",
        "\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    colors = {'TP': '#22c55e', 'FP': '#ef4444', 'FN': '#f97316', 'TN': '#3b82f6'}\n",
        "\n",
        "    for i, (idx, row) in enumerate(df_stats.iterrows()):\n",
        "        if i < 3:\n",
        "            ax = axes[i]\n",
        "            values = [row['TP'], row['FP'], row['FN'], row['TN']]\n",
        "            labels = ['TP', 'FP', 'FN', 'TN']\n",
        "            colors_list = [colors[label] for label in labels]\n",
        "\n",
        "            non_zero_data = [(val, lab, col) for val, lab, col in zip(values, labels, colors_list) if val > 0]\n",
        "            if non_zero_data:\n",
        "                values_nz, labels_nz, colors_nz = zip(*non_zero_data)\n",
        "\n",
        "                wedges, texts, autotexts = ax.pie(values_nz, labels=labels_nz, colors=colors_nz,\n",
        "                                                 autopct=lambda pct: f'{pct:.1f}%' if pct > 5 else '',\n",
        "                                                 startangle=90)\n",
        "\n",
        "                class_name = class_names[i] if i < len(class_names) else f'Class {i}'\n",
        "                ax.set_title(f'{class_name}\\nTotal: {sum(values)}', fontweight='bold')\n",
        "\n",
        "                for autotext in autotexts:\n",
        "                    autotext.set_color('white')\n",
        "                    autotext.set_fontweight('bold')\n",
        "                    autotext.set_fontsize(9)\n",
        "            else:\n",
        "                class_name = class_names[i] if i < len(class_names) else f'Class {i}'\n",
        "                ax.text(0.5, 0.5, f'{class_name}\\nNo Data',\n",
        "                       ha='center', va='center', transform=ax.transAxes)\n",
        "                ax.set_title(f'{class_name}', fontweight='bold')\n",
        "\n",
        "    for i in range(len(df_stats), 3):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "_9hqnJHFGkKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats, metrics = compute_confusion_stats(model_custom)\n",
        "\n",
        "print(df_stats)\n",
        "print(\"\\n\")\n",
        "\n",
        "plot_confusion_stats(df_stats, classes)"
      ],
      "metadata": {
        "id": "DNNMSOs_dwwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats, metrics = compute_confusion_stats(model_custom2)\n",
        "\n",
        "print(df_stats)\n",
        "print(\"\\n\")\n",
        "\n",
        "plot_confusion_stats(df_stats, classes)"
      ],
      "metadata": {
        "id": "mFK0CtXfb1yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LIME integraion for explanation**"
      ],
      "metadata": {
        "id": "o-_yQZ6vw9ZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime\n",
        "!pip install scikit-image"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mZIP69zYXxaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "8qjVzjnKYlce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLOWrapper:\n",
        "    def __init__(self, model, target_class_name):\n",
        "        self.model = model\n",
        "        self.target_class_name = target_class_name\n",
        "\n",
        "    def predict(self, images):\n",
        "        preds = []\n",
        "        for img in images:\n",
        "\n",
        "            img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "            results = self.model(img_bgr)[0]\n",
        "\n",
        "            class_names = results.names\n",
        "            detections = results.boxes\n",
        "            if detections is not None:\n",
        "                classes = detections.cls.cpu().numpy()\n",
        "                scores = detections.conf.cpu().numpy()\n",
        "                labels = [class_names[int(c)] for c in classes]\n",
        "\n",
        "                if self.target_class_name in labels:\n",
        "                    preds.append([1])\n",
        "                    continue\n",
        "            preds.append([0])\n",
        "        return np.array(preds)"
      ],
      "metadata": {
        "id": "h9f9JkT2Yng9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_selected_img=1"
      ],
      "metadata": {
        "id": "kq0KERzXbvGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_images_with_class(model, target_class_name, image_folder, num_images=num_selected_img, image_size=640):\n",
        "\n",
        "    image_folder = Path(image_folder)\n",
        "    image_paths = list(image_folder.glob(\"*.jpg\")) + list(image_folder.glob(\"*.png\"))\n",
        "    random.shuffle(image_paths)\n",
        "\n",
        "    selected = []\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img = np.array(Image.open(img_path).convert(\"RGB\").resize((image_size, image_size)))\n",
        "        img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        results = model(img_bgr)[0]\n",
        "\n",
        "        if results.boxes is not None:\n",
        "            predicted_classes = [results.names[int(c)] for c in results.boxes.cls.cpu().numpy()]\n",
        "            if target_class_name in predicted_classes:\n",
        "                selected.append(img_path)\n",
        "\n",
        "        if len(selected) >= num_images:\n",
        "            break\n",
        "\n",
        "    return selected"
      ],
      "metadata": {
        "id": "eqHYMOn-Id0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_images_with_class_from_list(model, target_class_name, image_list, image_folder,  image_size=640):\n",
        "\n",
        "    image_folder = Path(image_folder)\n",
        "    image_paths = [image_folder / fname for fname in image_list]\n",
        "    random.shuffle(image_paths)\n",
        "\n",
        "    selected = []\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img = np.array(Image.open(img_path).convert(\"RGB\").resize((image_size, image_size)))\n",
        "        img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "        results = model(img_bgr)[0]\n",
        "\n",
        "        if results.boxes is not None:\n",
        "            predicted_classes = [results.names[int(c)] for c in results.boxes.cls.cpu().numpy()]\n",
        "            if target_class_name in predicted_classes:\n",
        "                selected.append(img_path)\n",
        "\n",
        "    return selected"
      ],
      "metadata": {
        "id": "TjVZamSbMQti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = \"/content/drive/MyDrive/yolo_data/images/val\"\n",
        "image_list = [f\"maksssksksss748.png\"]\n",
        "target_class = classes[2]\n",
        "result = get_images_with_class_from_list(model_custom2 , target_class, image_list, image_folder)"
      ],
      "metadata": {
        "id": "rCRuWMwSLa69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_image_folder = Path(\"/content/drive/MyDrive/yolo_data/images/val\")"
      ],
      "metadata": {
        "id": "Q2EdXtSwYpRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detailed_lime_explanation(model, target_class_name, image_paths, image_size=640):\n",
        "    explainer = lime_image.LimeImageExplainer()\n",
        "    wrapped_model = YOLOWrapper(model, target_class_name)\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        print(f\"\\nImage analysis: {img_path.name}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        img = np.array(Image.open(img_path).convert(\"RGB\").resize((image_size, image_size)))\n",
        "\n",
        "        segmentation_configs = [\n",
        "            {\"n_segments\": 50, \"compactness\": 15, \"name\": \"Basic (50 segments)\"},\n",
        "            {\"n_segments\": 100, \"compactness\": 10, \"name\": \"Detailed (100 segments)\"},\n",
        "            {\"n_segments\": 200, \"compactness\": 5, \"name\": \"Very detailed (200 segments)\"}\n",
        "        ]\n",
        "\n",
        "        fig, axes = plt.subplots(len(segmentation_configs), 5, figsize=(25, 5 * len(segmentation_configs)))\n",
        "        if len(segmentation_configs) == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "\n",
        "        for i, config in enumerate(segmentation_configs):\n",
        "            explanation = explainer.explain_instance(\n",
        "                image=img,\n",
        "                classifier_fn=wrapped_model.predict,\n",
        "                top_labels=1,\n",
        "                hide_color=0,\n",
        "                num_samples=1000,\n",
        "                segmentation_fn=lambda x: slic(x, n_segments=config[\"n_segments\"], compactness=config[\"compactness\"])\n",
        "            )\n",
        "\n",
        "            importance_values = dict(explanation.local_exp[explanation.top_labels[0]])\n",
        "\n",
        "            full_segments = explanation.segments\n",
        "            heatmap = np.zeros(img.shape[:2])\n",
        "\n",
        "            for segment_id, importance in importance_values.items():\n",
        "                segment_mask = (full_segments == segment_id)\n",
        "                heatmap[segment_mask] = importance\n",
        "\n",
        "            axes[i, 0].imshow(img)\n",
        "            axes[i, 0].set_title(f'Original\\n{config[\"name\"]}')\n",
        "            axes[i, 0].axis('off')\n",
        "\n",
        "            temp, mask = explanation.get_image_and_mask(\n",
        "                label=explanation.top_labels[0],\n",
        "                positive_only=True,\n",
        "                hide_rest=False,\n",
        "                num_features=5\n",
        "            )\n",
        "            axes[i, 1].imshow(mark_boundaries(temp, mask))\n",
        "            axes[i, 1].set_title('Top 5 Positive')\n",
        "            axes[i, 1].axis('off')\n",
        "\n",
        "            temp, mask = explanation.get_image_and_mask(\n",
        "                label=explanation.top_labels[0],\n",
        "                positive_only=False,\n",
        "                hide_rest=False,\n",
        "                num_features=10\n",
        "            )\n",
        "            axes[i, 2].imshow(mark_boundaries(temp, mask))\n",
        "            axes[i, 2].set_title('Top 10 Mixed')\n",
        "            axes[i, 2].axis('off')\n",
        "\n",
        "            im1 = axes[i, 3].imshow(heatmap, cmap='RdBu_r', alpha=0.8,\n",
        "                                   vmin=np.min(list(importance_values.values())),\n",
        "                                   vmax=np.max(list(importance_values.values())))\n",
        "            axes[i, 3].imshow(img, alpha=0.4)\n",
        "            axes[i, 3].set_title('Raw Importance\\n(Red=+, Blue=-)')\n",
        "            axes[i, 3].axis('off')\n",
        "            plt.colorbar(im1, ax=axes[i, 3], fraction=0.046, pad=0.04)\n",
        "\n",
        "            if np.max(heatmap) > np.min(heatmap):\n",
        "                heatmap_norm = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap))\n",
        "            else:\n",
        "                heatmap_norm = heatmap\n",
        "\n",
        "            im2 = axes[i, 4].imshow(heatmap_norm, cmap='viridis', alpha=0.8)\n",
        "            axes[i, 4].imshow(img, alpha=0.4)\n",
        "            axes[i, 4].set_title('Normalized\\n(Purple=Low, Yellow=High)')\n",
        "            axes[i, 4].axis('off')\n",
        "            plt.colorbar(im2, ax=axes[i, 4], fraction=0.046, pad=0.04)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "bs1ONlvuY0EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_predictions_and_explanations(model, target_class_name, image_paths):\n",
        "    wrapped_model = YOLOWrapper(model, target_class_name)\n",
        "\n",
        "    for img_path in image_paths:\n",
        "        img = np.array(Image.open(img_path).convert(\"RGB\").resize((640, 640)))\n",
        "\n",
        "        prediction = wrapped_model.predict([img])[0]\n",
        "        confidence = prediction[0]\n",
        "\n",
        "        print(f\"\\nImage: {img_path.name}\")\n",
        "        print(f\"Model confidence for class '{target_class_name}': {confidence:.4f}\")"
      ],
      "metadata": {
        "id": "MsBIzNmdSakb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_class = classes[1]"
      ],
      "metadata": {
        "id": "5e9JlK_3LaJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_images = get_images_with_class(\n",
        "    model=model_custom2,\n",
        "    target_class_name=target_class,\n",
        "    image_folder=val_image_folder,\n",
        "    num_images=num_selected_img\n",
        ")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "I3HAit4iLaBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(selected_images)"
      ],
      "metadata": {
        "id": "xYgJX81K6zU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n3. Detailed LIME analysis of correct predictions:\")\n",
        "print(\"-\" * 50)\n",
        "compare_predictions_and_explanations(model_custom2, target_class, selected_images)\n",
        "detailed_lime_explanation(model_custom2, target_class, selected_images)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "11z9ABATLuFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n3. Detailed LIME analysis of correct predictions:\") #with fp\n",
        "print(\"-\" * 50)\n",
        "compare_predictions_and_explanations(model_custom2, target_class, result)\n",
        "detailed_lime_explanation(model_custom2, target_class, result)"
      ],
      "metadata": {
        "id": "I70YOtfKNQoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset correction with augmentation to try to better detect improperly worn masks**"
      ],
      "metadata": {
        "id": "18kJuY6FE-Iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "from scipy import ndimage"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JI--9S7CFoja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastBasedMaskAugmentation:\n",
        "    def __init__(self):\n",
        "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    def get_face_region(self, image):\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "        if len(faces) > 0:\n",
        "            x, y, w, h = max(faces, key=lambda f: f[2] * f[3])\n",
        "            return {'x': x, 'y': y, 'w': w, 'h': h}\n",
        "        return None\n",
        "\n",
        "    def analyze_face_contrast(self, image, face_region):\n",
        "        if face_region is None:\n",
        "            return None\n",
        "\n",
        "        x, y, w, h = face_region['x'], face_region['y'], face_region['w'], face_region['h']\n",
        "\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        face_gray = gray[y:y+h, x:x+w]\n",
        "\n",
        "        zones = {\n",
        "            'forehead': face_gray[0:int(h*0.3), :],\n",
        "            'eyes': face_gray[int(h*0.2):int(h*0.5), :],\n",
        "            'nose': face_gray[int(h*0.35):int(h*0.65), :],\n",
        "            'mouth': face_gray[int(h*0.6):int(h*0.8), :],\n",
        "            'chin': face_gray[int(h*0.75):h, :],\n",
        "            'left_cheek': face_gray[int(h*0.4):int(h*0.7), 0:int(w*0.3)],\n",
        "            'right_cheek': face_gray[int(h*0.4):int(h*0.7), int(w*0.7):w],\n",
        "        }\n",
        "\n",
        "        contrast_stats = {}\n",
        "\n",
        "        for zone_name, zone_img in zones.items():\n",
        "            if zone_img.size == 0:\n",
        "                continue\n",
        "\n",
        "            mean_intensity = np.mean(zone_img)\n",
        "            std_intensity = np.std(zone_img)\n",
        "\n",
        "            local_contrast = np.max(zone_img) - np.min(zone_img)\n",
        "\n",
        "            grad_x = cv2.Sobel(zone_img, cv2.CV_64F, 1, 0, ksize=3)\n",
        "            grad_y = cv2.Sobel(zone_img, cv2.CV_64F, 0, 1, ksize=3)\n",
        "            gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
        "            avg_gradient = np.mean(gradient_magnitude)\n",
        "\n",
        "            contrast_stats[zone_name] = {\n",
        "                'mean': mean_intensity,\n",
        "                'std': std_intensity,\n",
        "                'local_contrast': local_contrast,\n",
        "                'gradient': avg_gradient,\n",
        "                'contrast_ratio': std_intensity / (mean_intensity + 1e-6)\n",
        "            }\n",
        "\n",
        "        return contrast_stats, face_gray\n",
        "\n",
        "    def detect_incorrect_mask_by_contrast(self, contrast_stats):\n",
        "        if not contrast_stats:\n",
        "            return False, \"no_face\"\n",
        "\n",
        "        nose_contrast = contrast_stats.get('nose', {}).get('contrast_ratio', 0)\n",
        "        mouth_contrast = contrast_stats.get('mouth', {}).get('contrast_ratio', 0)\n",
        "        chin_contrast = contrast_stats.get('chin', {}).get('contrast_ratio', 0)\n",
        "\n",
        "        forehead_contrast = contrast_stats.get('forehead', {}).get('contrast_ratio', 0)\n",
        "        left_cheek_contrast = contrast_stats.get('left_cheek', {}).get('contrast_ratio', 0)\n",
        "        right_cheek_contrast = contrast_stats.get('right_cheek', {}).get('contrast_ratio', 0)\n",
        "\n",
        "        masked_avg_contrast = np.mean([forehead_contrast, left_cheek_contrast, right_cheek_contrast])\n",
        "\n",
        "        nose_suspicious = nose_contrast > masked_avg_contrast * 1.5\n",
        "        mouth_suspicious = mouth_contrast > masked_avg_contrast * 1.3\n",
        "        chin_suspicious = chin_contrast > masked_avg_contrast * 1.2\n",
        "\n",
        "        is_incorrect = nose_suspicious or mouth_suspicious or chin_suspicious\n",
        "\n",
        "        reason = []\n",
        "        if nose_suspicious: reason.append(\"exposed_nose\")\n",
        "        if mouth_suspicious: reason.append(\"exposed_mouth\")\n",
        "        if chin_suspicious: reason.append(\"exposed_chin\")\n",
        "\n",
        "        return is_incorrect, reason\n",
        "\n",
        "    def create_contrast_based_fake_masks(self, correct_mask_image):\n",
        "        face_region = self.get_face_region(correct_mask_image)\n",
        "        if face_region is None:\n",
        "            return correct_mask_image\n",
        "\n",
        "        img_copy = correct_mask_image.copy()\n",
        "        x, y, w, h = face_region['x'], face_region['y'], face_region['w'], face_region['h']\n",
        "\n",
        "        nose_y1 = y + int(h * 0.35)\n",
        "        nose_y2 = y + int(h * 0.65)\n",
        "        nose_x1 = x + int(w * 0.3)\n",
        "        nose_x2 = x + int(w * 0.7)\n",
        "\n",
        "        nose_region = img_copy[nose_y1:nose_y2, nose_x1:nose_x2]\n",
        "\n",
        "        brightened = cv2.convertScaleAbs(nose_region, alpha=1.3, beta=20)\n",
        "\n",
        "        brightened[:,:,0] = np.clip(brightened[:,:,0] * 0.9, 0, 255)\n",
        "        brightened[:,:,1] = np.clip(brightened[:,:,1] * 1.1, 0, 255)\n",
        "        brightened[:,:,2] = np.clip(brightened[:,:,2] * 1.2, 0, 255)\n",
        "\n",
        "        noise = np.random.normal(0, 8, brightened.shape).astype(np.int16)\n",
        "        brightened = np.clip(brightened.astype(np.int16) + noise, 0, 255).astype(np.uint8)\n",
        "\n",
        "        img_copy[nose_y1:nose_y2, nose_x1:nose_x2] = brightened\n",
        "\n",
        "        return img_copy\n",
        "\n",
        "    def augment_for_contrast_detection(self, image):\n",
        "\n",
        "        enhance_contrast = A.Compose([\n",
        "            A.CLAHE(clip_limit=3.0, tile_grid_size=(8, 8), p=0.9),\n",
        "            A.UnsharpMask(blur_limit=5, alpha=0.3, p=0.7),\n",
        "        ])\n",
        "\n",
        "        edge_enhance = A.Compose([\n",
        "          A.Sharpen(alpha=(0.1, 0.3), lightness=(0.8, 1.2), p=0.8),\n",
        "          A.Emboss(alpha=(0.05, 0.15), strength=(0.3, 0.7), p=0.3),\n",
        "        ])\n",
        "\n",
        "\n",
        "        color_contrast = A.Compose([\n",
        "            A.HueSaturationValue(\n",
        "                hue_shift_limit=8,\n",
        "                sat_shift_limit=15,\n",
        "                val_shift_limit=15,\n",
        "                p=0.7\n",
        "            ),\n",
        "            A.RandomBrightnessContrast(\n",
        "                brightness_limit=0.15,\n",
        "                contrast_limit=0.25,\n",
        "                p=0.8\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "        image = enhance_contrast(image=image)['image']\n",
        "        image = edge_enhance(image=image)['image']\n",
        "        image = color_contrast(image=image)['image']\n",
        "\n",
        "        return image\n"
      ],
      "metadata": {
        "id": "pS2uG87HELOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir_aug=\"/content/drive/MyDrive/yolo_data/dataset_aug1\""
      ],
      "metadata": {
        "id": "j8HfWFXJIZF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " os.makedirs(f\"{output_dir_aug}\", exist_ok=True)"
      ],
      "metadata": {
        "id": "zge1kQwIHbrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_yolo_dataset_with_contrast_universal(dataset_dir, output_dir, analyze_existing=True):\n",
        "    augmenter = ContrastBasedMaskAugmentation()\n",
        "\n",
        "    os.makedirs(f\"{output_dir}/images/train\", exist_ok=True)\n",
        "    os.makedirs(f\"{output_dir}/images/val\", exist_ok=True)\n",
        "    os.makedirs(f\"{output_dir}/labels/train\", exist_ok=True)\n",
        "    os.makedirs(f\"{output_dir}/labels/val\", exist_ok=True)\n",
        "\n",
        "    labels_folder = None\n",
        "    possible_labels_names = ['labels', 'annotations', 'annotation', 'ann']\n",
        "\n",
        "    for name in possible_labels_names:\n",
        "        if os.path.exists(os.path.join(dataset_dir, name)):\n",
        "            labels_folder = name\n",
        "            print(f\"Found labels folder: {name}\")\n",
        "            break\n",
        "\n",
        "    if not labels_folder:\n",
        "        print(\"Warning: No labels folder found! Looking for: labels, annotations, annotation, ann\")\n",
        "        return None\n",
        "\n",
        "    stats = {\n",
        "        'total_processed': 0,\n",
        "        'incorrect_masks_found': 0,\n",
        "        'synthetic_created': 0,\n",
        "        'contrast_analysis': [],\n",
        "        'train_stats': {'processed': 0, 'augmented': 0},\n",
        "        'val_stats': {'processed': 0, 'augmented': 0}\n",
        "    }\n",
        "\n",
        "    for split in ['train', 'val']:\n",
        "        images_dir = os.path.join(dataset_dir, 'images', split)\n",
        "        labels_dir = os.path.join(dataset_dir, labels_folder, split)\n",
        "\n",
        "        if not os.path.exists(images_dir):\n",
        "            if split == 'train':\n",
        "                images_dir = os.path.join(dataset_dir, 'images')\n",
        "                labels_dir = os.path.join(dataset_dir, labels_folder)\n",
        "                print(f\"Using main directories (no train/val split found)\")\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "        if not os.path.exists(images_dir) or not os.listdir(images_dir):\n",
        "            print(f\"Skipping {split} - directory empty or doesn't exist\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nProcessing {split} split...\")\n",
        "        print(f\"Images dir: {images_dir}\")\n",
        "        print(f\"Labels dir: {labels_dir}\")\n",
        "\n",
        "        image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        print(f\"Found {len(image_files)} image files\")\n",
        "\n",
        "        for img_file in image_files:\n",
        "            print(f\"Analyzing image: {img_file}\")\n",
        "            img_path = os.path.join(images_dir, img_file)\n",
        "            label_path = os.path.join(labels_dir, img_file.rsplit('.', 1)[0] + '.txt')\n",
        "\n",
        "            image = cv2.imread(img_path)\n",
        "            if image is None:\n",
        "                print(f\"  Warning: Could not load image {img_file}\")\n",
        "                continue\n",
        "\n",
        "            face_region = augmenter.get_face_region(image)\n",
        "            if face_region:\n",
        "                contrast_stats, face_gray = augmenter.analyze_face_contrast(image, face_region)\n",
        "                is_incorrect, reasons = augmenter.detect_incorrect_mask_by_contrast(contrast_stats)\n",
        "\n",
        "                print(f\"  Contrast analysis: {'incorrect' if is_incorrect else 'correct'}\")\n",
        "                if is_incorrect:\n",
        "                    print(f\"  Reasons: {', '.join(reasons)}\")\n",
        "\n",
        "                stats['contrast_analysis'].append({\n",
        "                    'file': img_file,\n",
        "                    'split': split,\n",
        "                    'is_incorrect': is_incorrect,\n",
        "                    'reasons': reasons,\n",
        "                    'nose_contrast': contrast_stats.get('nose', {}).get('contrast_ratio', 0),\n",
        "                    'mouth_contrast': contrast_stats.get('mouth', {}).get('contrast_ratio', 0)\n",
        "                })\n",
        "            else:\n",
        "                print(f\"  No face detected in {img_file}\")\n",
        "\n",
        "            if os.path.exists(label_path):\n",
        "                with open(label_path, 'r') as f:\n",
        "                    labels = f.readlines()\n",
        "\n",
        "                has_incorrect_mask = any('2 ' in label for label in labels)\n",
        "\n",
        "                if has_incorrect_mask:\n",
        "                    stats['incorrect_masks_found'] += 1\n",
        "                    stats[f'{split}_stats']['augmented'] += 1\n",
        "\n",
        "                    augmented_image = augmenter.augment_for_contrast_detection(image)\n",
        "\n",
        "                    aug_img_path = f\"{output_dir}/images/{split}/aug_{img_file}\"\n",
        "                    aug_label_path = f\"{output_dir}/labels/{split}/aug_{img_file.rsplit('.', 1)[0]}.txt\"\n",
        "\n",
        "                    cv2.imwrite(aug_img_path, augmented_image)\n",
        "                    with open(aug_label_path, 'w') as f:\n",
        "                        f.writelines(labels)\n",
        "\n",
        "                    print(f\"Created augmented data: aug_{img_file}\")\n",
        "                    stats['synthetic_created'] += 1\n",
        "                else:\n",
        "                    print(f\"  No incorrect masks found, skipping augmentation\")\n",
        "            else:\n",
        "                print(f\"  Warning: Label file not found: {label_path}\")\n",
        "\n",
        "            stats['total_processed'] += 1\n",
        "            stats[f'{split}_stats']['processed'] += 1\n",
        "\n",
        "        if split == 'train' and images_dir == os.path.join(dataset_dir, 'images'):\n",
        "            break\n",
        "\n",
        "    print(f\"Total images processed: {stats['total_processed']}\")\n",
        "    print(f\"Images with incorrect masks: {stats['incorrect_masks_found']}\")\n",
        "    print(f\"Synthetic images created: {stats['synthetic_created']}\")\n",
        "    print(f\"Train - Processed: {stats['train_stats']['processed']}, Augmented: {stats['train_stats']['augmented']}\")\n",
        "\n",
        "    return stats"
      ],
      "metadata": {
        "id": "67f8hvrfGlne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copy_folder_contents(src_dir, dst_dir):\n",
        "    if not os.path.exists(src_dir):\n",
        "        print(f\"source do not exist: {src_dir}\")\n",
        "        return\n",
        "\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "    for item in os.listdir(src_dir):\n",
        "        s = os.path.join(src_dir, item)\n",
        "        d = os.path.join(dst_dir, item)\n",
        "\n",
        "        if os.path.isdir(s):\n",
        "            shutil.copytree(s, d, dirs_exist_ok=True)\n",
        "        else:\n",
        "            shutil.copy2(s, d)\n",
        "\n",
        "    print(f\"content was copied from: \\n{src_dir}\\n to: \\n{dst_dir}\")"
      ],
      "metadata": {
        "id": "QlO45OLleUMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = \"/content/drive/MyDrive/yolo_data\"\n",
        "output_dir_aug = \"/content/drive/MyDrive/yolo_data/dataset_aug1\"\n",
        "\n",
        "stats = process_yolo_dataset_with_contrast_universal(dataset_dir, output_dir_aug)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XGVRnz8uKUaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_folder_contents(\"/content/drive/MyDrive/yolo_data/images/val\",\"/content/drive/MyDrive/yolo_data/dataset_aug1/images/val\" )"
      ],
      "metadata": {
        "id": "1019mPD4Trdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "copy_folder_contents(\"/content/drive/MyDrive/yolo_data/labels/val\",\"/content/drive/MyDrive/yolo_data/dataset_aug1/images/val\" )"
      ],
      "metadata": {
        "id": "_nVoOZJ-e-wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training YOLO with dataset with augmentation**"
      ],
      "metadata": {
        "id": "8jNfOo3XuZvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = YOLO('yolov5m.pt')"
      ],
      "metadata": {
        "id": "WAdpSRNhznGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destination_dir = '/content/drive/MyDrive/yolo_data/yolo_training_results3'\n",
        "os.makedirs(os.path.dirname(destination_dir), exist_ok=True)"
      ],
      "metadata": {
        "id": "I49CXZYyz2nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.train(data=\"/content/drive/MyDrive/yolo_data/mask_detection_aug.yaml\", epochs=50, imgsz=640)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "a2UgyKMYVIYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom3 = YOLO(\"/content/drive/MyDrive/yolo_data/yolo_training_results3/train3/weights/best.pt\")"
      ],
      "metadata": {
        "id": "8lWLwReacrOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_custom3.predict(\n",
        "    source='/content/drive/MyDrive/yolo_data/images/val',\n",
        "    save=True,\n",
        "    save_txt=True,\n",
        "    save_conf=True,\n",
        "    project='prediction3',\n",
        "    name='yolov5m_predictions',\n",
        "    exist_ok=True\n",
        ")"
      ],
      "metadata": {
        "id": "GPUfbPCGU2FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/prediction3 /content/drive/MyDrive/yolo_data/"
      ],
      "metadata": {
        "id": "XxdZIhPAVH99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **augmentation YOLO testing, TP, TN, FP, FN**"
      ],
      "metadata": {
        "id": "Co8bT_FTvrLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats, metrics = compute_confusion_stats(model_custom3)\n",
        "\n",
        "print(df_stats)\n",
        "print(\"\\n\")\n",
        "\n",
        "plot_confusion_stats(df_stats, classes)"
      ],
      "metadata": {
        "id": "GOkj7Pa4vhV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Improving parameters in training**"
      ],
      "metadata": {
        "id": "Hp7TXCRvI9zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = YOLO('yolov5m.pt')"
      ],
      "metadata": {
        "id": "bSb4qaw-JhD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3.train(\n",
        "    data=\"/content/drive/MyDrive/yolo_data/mask_detection.yaml\",\n",
        "    epochs=100,\n",
        "\n",
        "    imgsz=640,\n",
        "    batch=16,\n",
        "    box=5.0,\n",
        "    cls=1.0\n",
        ")"
      ],
      "metadata": {
        "id": "6BXejicYI8e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "destination_dir = '/content/drive/MyDrive/yolo_data/yolo_training_results4'\n",
        "os.makedirs(os.path.dirname(destination_dir), exist_ok=True)"
      ],
      "metadata": {
        "id": "6pxn_rE-UMN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = '/content/runs'\n",
        "shutil.copytree(source_dir, destination_dir, dirs_exist_ok=True)"
      ],
      "metadata": {
        "id": "DNnuYCq5UWZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_custom4 = YOLO(\"/content/drive/MyDrive/yolo_data/yolo_training_results4/train/weights/best.pt\")"
      ],
      "metadata": {
        "id": "WC1ww706_Hxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_stats, metrics = compute_confusion_stats(model_custom4)\n",
        "\n",
        "print(df_stats)\n",
        "print(\"\\n\")\n",
        "\n",
        "plot_confusion_stats(df_stats, classes)"
      ],
      "metadata": {
        "id": "Z6nxTafWkNbc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}